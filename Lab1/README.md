## Параллельная реализация решения системы линейных алгебраических уравнений с помощью MPI

### Цель работы

Ознакомиться с функционалом MPI. Реализовать метод решения системы линейных алгебраических уравнений, применяя инструменты MPI для параллельной работы с данными.

### Задание

1.  Написать программу на языке C или C++, которая реализует итерационный алгоритм решения системы линейных алгебраических уравнений вида Ax=b в соответствии с выбранным вариантом. Здесь A – матрица размером N×N, x и b – векторы длины N. Тип элементов – double.
2.  Программу распараллелить с помощью MPI с разрезанием матрицы A по строкам на близкие по размеру, возможно не одинаковые, части. Соседние строки матрицы должны располагаться в одном или в соседних MPI-процессах. Реализовать два варианта программы:
    •   Вариант 1: векторы x и b дублируются в каждом MPI-процессе,
    •   Вариант 2: векторы x и b разрезаются между MPI-процессами аналогично матрице A. Уделить внимание тому, чтобы при запуске программы на различном числе MPI-процессов решалась одна и та же задача (исходные данные заполнялись одинаковым образом).
3.  Замерить время работы двух вариантов программы при использовании различного числа процессорных ядер: 1,2, 4, 8, 16. Построить графики зависимости времени работы программы, ускорения и эффективности распараллеливания от числа используемых ядер. Исходные данные, параметры N и ε подобрать таким образом, чтобы решение задачи на одном ядре занимало не менее 30 секунд.
4.  Выполнить профилирование двух вариантов программы с помощью MPE при использовании 16-и ядер.
5.  На основании полученных результатов сделать вывод о целесообразности использования одного или второго варианта программы.

### Описание работы

#### Ход работы:

1.  Я написал программу на C++, реализующую последовательный алгоритм для моего варианта – метод минимальных невязок.

2.  С помощью библиотеки MPI я распараллелил программу двумя способами и проверил корректность работы на предложенной задаче для разного количества процессов при разных значениях N (размер матрицы).

3.  После я замерил время работы последовательной и параллельных программ на кластере. По полученным данным я построил графики – зависимость времени от количества процессов, график ускорения и график эффективности (в процентах).

4.  Далее я провёл профилирование для каждого из двух параллельных вариантов при использовании 24-х ядер.

#### Графики:

` Замеры проводились при N = 18000` <br>
` Время выполнения последовательной программы составило 37 секунд`

![image](https://user-images.githubusercontent.com/44488666/120066198-af669200-c09f-11eb-9986-c882f5348656.png)
![image](https://user-images.githubusercontent.com/44488666/120066212-c86f4300-c09f-11eb-8a83-d3ed49bf3e1b.png)
![image](https://user-images.githubusercontent.com/44488666/120066232-de7d0380-c09f-11eb-9e13-b22beed8297a.png)

#### Таблицы замеров:

![image](https://user-images.githubusercontent.com/44488666/120066216-cb6a3380-c09f-11eb-8cc6-f82149be009c.png)

#### Профилирование:

*Вариант 1*

![image](https://user-images.githubusercontent.com/44488666/120066284-24d26280-c0a0-11eb-848e-b1ee36402578.png)

*Вариант 2*

![image](https://user-images.githubusercontent.com/44488666/120066286-269c2600-c0a0-11eb-991a-bc75b07d3779.png)

### Заключение

В ходе выполнения лабораторной работы я научился использовать базовые функции библиотеки MPI, узнал о способах распараллеливания программы, их различиях и преимуществах. Реализовал алгоритм минимальных невязок и на примере убедился в выгодности параллельного способа реализации.
